{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMJChUT8/U5IemHlEgasHZP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pranavkantgaur/training_materials/blob/master/ACT_demos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Common Imports\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import random"
      ],
      "metadata": {
        "id": "Oli8pc5AKGXu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Context: Naive Monte Carlo Simulation\n",
        "\n",
        "Objective: Implement a serial neutron absorption simulator."
      ],
      "metadata": {
        "id": "a3CZuC_YKNFO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def simulate_serial(N=10000, p_abs=0.01, max_steps=100):\n",
        "    absorbed = 0\n",
        "    random.seed(42)\n",
        "    for _ in range(N):\n",
        "        for _ in range(max_steps):\n",
        "            if random.random() < p_abs:\n",
        "                absorbed += 1\n",
        "                break\n",
        "    return absorbed\n",
        "\n",
        "# Runtime and accuracy test\n",
        "start = time.time()\n",
        "result = simulate_serial(10000)  # Smaller N for quick demo\n",
        "print(f\"Absorbed: {result} | Time: {time.time() - start:.2f}s\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YICFiNoKKIrk",
        "outputId": "03e9fb75-e9e5-43a2-97f6-c6f8bd66a472"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Absorbed: 6346 | Time: 0.04s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explanation:\n",
        "\n",
        "    Each neutron is simulated independently with a loop-in-loop structure.\n",
        "\n",
        "    p_abs=0.01 means a 1% chance of absorption per step.\n",
        "\n"
      ],
      "metadata": {
        "id": "GC4X5djyKSrU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## C++ version"
      ],
      "metadata": {
        "id": "IdRY3eX1fGV1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "cat << 'EOF' > neutron.cpp\n",
        "#include <iostream>\n",
        "#include <random>\n",
        "#include <chrono>\n",
        "\n",
        "int simulate_cpp(int N=10000, double p_abs=0.01, int max_steps=100) {\n",
        "    std::random_device rd;\n",
        "    std::mt19937 gen(rd());\n",
        "    std::uniform_real_distribution<> dis(0.0, 1.0);\n",
        "\n",
        "    int absorbed = 0;\n",
        "    for (int i = 0; i < N; ++i) {\n",
        "        for (int step = 0; step < max_steps; ++step) {\n",
        "            if (dis(gen) < p_abs) {\n",
        "                absorbed++;\n",
        "                break;\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "    return absorbed;\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    auto start = std::chrono::high_resolution_clock::now();\n",
        "    int result = simulate_cpp();\n",
        "    auto end = std::chrono::high_resolution_clock::now();\n",
        "    std::chrono::duration<double> elapsed = end - start;\n",
        "    std::cout << \"C++ Result: \" << result\n",
        "              << \" | Time: \" << elapsed.count() << \"s\\n\";\n",
        "    return 0;\n",
        "}\n",
        "EOF"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "piP50WlRpBzK",
        "outputId": "f28b2af4-71d6-4f25-e6ab-e6e96daa90b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "# Compile C++ code with optimizations\n",
        "g++ -O3 -o neutron_simulation neutron.cpp\n",
        "./neutron_simulation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KSgxQdpKpH5u",
        "outputId": "6db9f025-fe7d-4878-8022-447b771b26e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "C++ Result: 6395 | Time: 0.011817s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Time profile serial implementation"
      ],
      "metadata": {
        "id": "HR7RFVzzfKiB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cProfile\n",
        "\n",
        "def simulate_serial(N=10000, p_abs=0.01, max_steps=100):\n",
        "    absorbed = 0\n",
        "    random.seed(42)\n",
        "    for _ in range(N):\n",
        "        for _ in range(max_steps):\n",
        "            if random.random() < p_abs:\n",
        "                absorbed += 1\n",
        "                break\n",
        "    return absorbed\n",
        "\n",
        "# Profile function\n",
        "cProfile.run('simulate_serial(10000)', sort='cumulative')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dHQjeFAqqQUL",
        "outputId": "f5094c6e-cef7-45e6-bcb4-90834302ffd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         635455 function calls in 0.196 seconds\n",
            "\n",
            "   Ordered by: cumulative time\n",
            "\n",
            "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
            "        1    0.000    0.000    0.196    0.196 {built-in method builtins.exec}\n",
            "        1    0.000    0.000    0.196    0.196 <string>:1(<module>)\n",
            "        1    0.147    0.147    0.196    0.196 <ipython-input-42-ecb417cdbb4f>:3(simulate_serial)\n",
            "   635447    0.048    0.000    0.048    0.000 {method 'random' of '_random.Random' objects}\n",
            "        1    0.000    0.000    0.000    0.000 random.py:128(seed)\n",
            "        1    0.000    0.000    0.000    0.000 {function Random.seed at 0x7b4b5bb90180}\n",
            "        2    0.000    0.000    0.000    0.000 {built-in method builtins.isinstance}\n",
            "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Line by line profiling"
      ],
      "metadata": {
        "id": "IJya8MfqfWbV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install line_profiler"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wvvpt-Z-sWPe",
        "outputId": "492497a8-72e3-4eef-aa6e-1dd857bb783a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting line_profiler\n",
            "  Downloading line_profiler-4.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (34 kB)\n",
            "Downloading line_profiler-4.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (750 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m750.2/750.2 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: line_profiler\n",
            "Successfully installed line_profiler-4.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def simulate_serial(N=10_000, p_abs=0.01, max_steps=100):\n",
        "    absorbed = 0\n",
        "    for _ in range(N):\n",
        "        for _ in range(max_steps):\n",
        "            if random.random() < p_abs:\n",
        "                absorbed += 1\n",
        "                break\n",
        "    return absorbed\n",
        "\n",
        "# Explicitly add the decorator (Colab workaround)\n",
        "from line_profiler import LineProfiler\n",
        "lp = LineProfiler()\n",
        "lp_wrapper = lp(simulate_serial)"
      ],
      "metadata": {
        "id": "UJiBogassYIL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Execute with profiling\n",
        "result = lp_wrapper()\n",
        "lp.print_stats()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Jg3xUlKsdyA",
        "outputId": "9620f6d8-2743-43bd-c939-c895e4cf4e53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timer unit: 1e-09 s\n",
            "\n",
            "Total time: 1.33926 s\n",
            "File: <ipython-input-4-47fe190b5943>\n",
            "Function: simulate_serial at line 4\n",
            "\n",
            "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
            "==============================================================\n",
            "     4                                           def simulate_serial(N=10_000, p_abs=0.01, max_steps=100):\n",
            "     5         1       1384.0   1384.0      0.0      absorbed = 0\n",
            "     6     10001   12482288.0   1248.1      0.9      for _ in range(N):\n",
            "     7    639367  454249092.0    710.5     33.9          for _ in range(max_steps):\n",
            "     8    635750  865666756.0   1361.6     64.6              if random.random() < p_abs:\n",
            "     9      6383    3841695.0    601.9      0.3                  absorbed += 1\n",
            "    10      6383    3016845.0    472.6      0.2                  break\n",
            "    11         1        833.0    833.0      0.0      return absorbed\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Assignment:\n",
        "1. How to improve the runtime performance without resorting to parallelization/vectorization?"
      ],
      "metadata": {
        "id": "1Kdy0oktp2YM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### How the above line_profiler works? (Decorators)"
      ],
      "metadata": {
        "id": "sPg0cYvPGKxO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleDecorator:\n",
        "    def __init__(self, func):\n",
        "        self.func = func  # Store the original function\n",
        "\n",
        "    def __call__(self, *args, **kwargs):\n",
        "        \"\"\"This gets called when the decorated function is invoked\"\"\"\n",
        "        print(f\"Before calling {self.func.__name__}\")\n",
        "        result = self.func(*args, **kwargs)  # Execute original function\n",
        "        print(f\"After calling {self.func.__name__}\")\n",
        "        return result\n",
        "\n",
        "'''\n",
        "# Usage\n",
        "@SimpleDecorator\n",
        "def hello(name):\n",
        "    print(f\"Hello, {name}!\")\n",
        "# Test it\n",
        "#hello(\"Alice\")\n",
        "'''\n",
        "sd = SimpleDecorator(hello)\n",
        "sd(\"Alice\")\n",
        "#hello(\"Alice\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v-G-ui_qEXe2",
        "outputId": "d1dcccb5-daf0-4cd7-d6e1-21d215881d37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello, Alice!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Why line_profiler is not designed with interface like cProfile?\n",
        "\n",
        "1. To profile individual lines (not just function calls), line_profiler must instrument the function line-by-line. This requires wrapping the function explicitly.\n",
        "2. cProfile operates at the function-call level, which is simpler to implement without modifying the target code.\n"
      ],
      "metadata": {
        "id": "OcQxRQJeGpbf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Before vectorizaton, can Cython help here?"
      ],
      "metadata": {
        "id": "PJSEFqCNIqar"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 1: Install required packages\n",
        "!pip install line_profiler cython"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ocDbooQFIwcT",
        "outputId": "d6892c48-cccb-4c63-d036-f43be2f83e4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting line_profiler\n",
            "  Downloading line_profiler-4.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (34 kB)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.11/dist-packages (3.0.12)\n",
            "Downloading line_profiler-4.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (750 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m750.2/750.2 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: line_profiler\n",
            "Successfully installed line_profiler-4.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Python code with seed control"
      ],
      "metadata": {
        "id": "Vd71U9-8Zpy6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Updated Python implementation with seed control\n",
        "import random\n",
        "\n",
        "def simulate_serial(N=10_000, p_abs=0.01, max_steps=100, seed=None):\n",
        "    if seed is not None:\n",
        "        random.seed(seed)\n",
        "\n",
        "    absorbed = 0\n",
        "    for _ in range(N):\n",
        "        for _ in range(max_steps):\n",
        "            if random.random() < p_abs:\n",
        "                absorbed += 1\n",
        "                break\n",
        "    return absorbed"
      ],
      "metadata": {
        "id": "I4Sw-Qe6ZoK6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%file simulate_cython.pyx\n",
        "# cython: linetrace=True\n",
        "# distutils: define_macros=CYTHON_TRACE_NOGIL=1\n",
        "\n",
        "from libc.stdlib cimport rand, srand, RAND_MAX\n",
        "\n",
        "def simulate_cython(int N=10_000, double p_abs=0.01, int max_steps=100, unsigned int seed=0):\n",
        "    cdef:\n",
        "        int absorbed = 0\n",
        "        int i, j\n",
        "        double rand_val\n",
        "\n",
        "    if seed != 0:\n",
        "        srand(seed)\n",
        "\n",
        "    for i in range(N):\n",
        "        for j in range(max_steps):\n",
        "            rand_val = <double>rand() / (RAND_MAX + 1.0)\n",
        "            if rand_val < p_abs:\n",
        "                absorbed += 1\n",
        "                break\n",
        "    return absorbed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17Zk5FSWI4d8",
        "outputId": "1d7bda9f-1f27-46a7-817e-7dd9896db080"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing simulate_cython.pyx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install build-essential"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K_rJl_2Kb3PG",
        "outputId": "926c6556-994f-4693-d0ec-6dbfc21dec7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "build-essential is already the newest version (12.9ubuntu3).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 29 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install python3-dev"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YThZcq_qb6rQ",
        "outputId": "d1ac9a9f-657f-4ba7-aa05-5e4af7ea71d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "python3-dev is already the newest version (3.10.6-1~22.04.1).\n",
            "python3-dev set to manually installed.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 29 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade setuptools"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        },
        "id": "20PlOqJAbvj5",
        "outputId": "c76bfb92-7103-4a28-92a5-ced078e70e0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (75.2.0)\n",
            "Collecting setuptools\n",
            "  Downloading setuptools-78.1.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Downloading setuptools-78.1.0-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m42.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: setuptools\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 75.2.0\n",
            "    Uninstalling setuptools-75.2.0:\n",
            "      Successfully uninstalled setuptools-75.2.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed setuptools-78.1.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "_distutils_hack"
                ]
              },
              "id": "3b9cdda9e12c4454818889a4a465132d"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from distutils.core import setup\n",
        "from Cython.Build import cythonize\n",
        "import sys, os\n",
        "\n",
        "# Workaround for Colab's temporary filesystem\n",
        "os.chdir('/content')\n",
        "# Add script_args to ignore Jupyter's -f flag\n",
        "setup(ext_modules=cythonize('simulate_cython.pyx', compiler_directives={'linetrace': True}), script_args=['build_ext', '--inplace'])\n",
        "#setup(ext_modules=cythonize('simulate_cython.pyx'), script_args=['build_ext', '--inplace'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W5v5X4UvJXzd",
        "outputId": "27c56a13-7e52-4247-f015-5f91f8a04bc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Compiling simulate_cython.pyx because it changed.\n",
            "[1/1] Cythonizing simulate_cython.pyx\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/Cython/Compiler/Main.py:381: FutureWarning: Cython directive 'language_level' not set, using '3str' for now (Py3). This has changed from earlier releases! File: /content/simulate_cython.pyx\n",
            "  tree = Parsing.p_module(s, pxd, full_module_name)\n",
            "INFO:root:running build_ext\n",
            "INFO:root:building 'simulate_cython' extension\n",
            "INFO:root:creating build/temp.linux-x86_64-cpython-311\n",
            "INFO:root:x86_64-linux-gnu-gcc -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -DCYTHON_TRACE_NOGIL=1 -I/usr/include/python3.11 -c simulate_cython.c -o build/temp.linux-x86_64-cpython-311/simulate_cython.o\n",
            "INFO:root:creating build/lib.linux-x86_64-cpython-311\n",
            "INFO:root:x86_64-linux-gnu-gcc -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 build/temp.linux-x86_64-cpython-311/simulate_cython.o -L/usr/lib/x86_64-linux-gnu -o build/lib.linux-x86_64-cpython-311/simulate_cython.cpython-311-x86_64-linux-gnu.so\n",
            "INFO:root:copying build/lib.linux-x86_64-cpython-311/simulate_cython.cpython-311-x86_64-linux-gnu.so -> \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<setuptools.dist.Distribution at 0x7ebcfc218b90>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyximport\n",
        "pyximport.install()\n",
        "\n",
        "import simulate_cython"
      ],
      "metadata": {
        "id": "GTzx8vt8Jflv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from line_profiler import LineProfiler\n",
        "\n",
        "lp_cy = LineProfiler()\n",
        "lp_wrapper_cy = lp_cy(simulate_cython.simulate_cython)\n",
        "%time result_cy = lp_wrapper_cy()\n",
        "print(f\"Cython result: {result_cy}\")\n",
        "lp_cy.print_stats()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Z-Zxx1dJlW9",
        "outputId": "a13e7e7b-5f8f-4efc-bfba-1f02a9a532cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 62.9 ms, sys: 757 µs, total: 63.7 ms\n",
            "Wall time: 63.5 ms\n",
            "Cython result: 6418\n",
            "Timer unit: 1e-09 s\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Common parameters with fixed seed\n",
        "SEED = 42\n",
        "N = 10_000\n",
        "P_ABS = 0.01\n",
        "MAX_STEPS = 100\n",
        "\n",
        "# Python version\n",
        "%time py_result = simulate_serial(N, P_ABS, MAX_STEPS, SEED)\n",
        "\n",
        "# Cython version (requires proper compilation from Step 3)\n",
        "%time cy_result = simulate_cython.simulate_cython()#(N, P_ABS, MAX_STEPS, seed=SEED)\n",
        "\n",
        "print(f\"Python result: {py_result}\")\n",
        "print(f\"Cython result: {cy_result}\")\n",
        "#print(f\"Relative difference: {abs(py_result - cy_result)/py_result:.2%}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "id": "uVajm8GoJo4b",
        "outputId": "c60ca5dd-ec19-4882-cf6c-f4da92571396"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'simulate_serial' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'simulate_serial' is not defined"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 13.4 ms, sys: 0 ns, total: 13.4 ms\n",
            "Wall time: 13.4 ms\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'py_result' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-1533971b2f1a>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cy_result = simulate_cython.simulate_cython()#(N, P_ABS, MAX_STEPS, seed=SEED)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Python result: {py_result}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Cython result: {cy_result}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m#print(f\"Relative difference: {abs(py_result - cy_result)/py_result:.2%}\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'py_result' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "TtmUcrc4duI-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /content/build/"
      ],
      "metadata": {
        "id": "3j-_QTX4SGoM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "OqgYbklfGy9b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vectorized Implementation\n",
        "\n",
        "Objective: Optimize using array operations."
      ],
      "metadata": {
        "id": "MMVTA1EhKXRm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### With Numpy"
      ],
      "metadata": {
        "id": "t6BCxgKcuyu8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from line_profiler import LineProfiler\n",
        "\n",
        "\n",
        "# Vectorized simulation\n",
        "def simulate_numpy(N=10_000, p_abs=0.01, max_steps=100):\n",
        "    # Generate all random numbers at once\n",
        "    steps = np.random.rand(N, max_steps)  # Shape: (N, max_steps)\n",
        "\n",
        "    # Check absorption per neutron (any step < p_abs)\n",
        "    absorbed = np.any(steps < p_abs, axis=1).sum()\n",
        "\n",
        "    return absorbed\n",
        "\n",
        "# Line-level runtime profiling\n",
        "lp = LineProfiler()\n",
        "lp.add_function(simulate_numpy) # Add the function to be profiled\n",
        "lp_wrapper = lp(simulate_numpy) # Wrap the function using lp\n",
        "\n",
        "# Execute with profiling, this will call the wrapped function\n",
        "result = lp_wrapper(N=10_000, p_abs=0.01, max_steps=100)\n",
        "\n",
        "# Print line profiling stats\n",
        "lp.print_stats()\n",
        "\n",
        "# Print memory profiling results (will be printed to the console)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nLgyudVLKaFi",
        "outputId": "8e503146-4934-46a5-99ce-ed33a03665eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timer unit: 1e-09 s\n",
            "\n",
            "Total time: 0.0284459 s\n",
            "File: <ipython-input-16-1d834d1b3a2b>\n",
            "Function: simulate_numpy at line 6\n",
            "\n",
            "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
            "==============================================================\n",
            "     6                                           def simulate_numpy(N=10_000, p_abs=0.01, max_steps=100):\n",
            "     7                                               # Generate all random numbers at once\n",
            "     8         1   23770421.0    2e+07     83.6      steps = np.random.rand(N, max_steps)  # Shape: (N, max_steps)\n",
            "     9                                           \n",
            "    10                                               # Check absorption per neutron (any step < p_abs)\n",
            "    11         1    4674967.0    5e+06     16.4      absorbed = np.any(steps < p_abs, axis=1).sum()\n",
            "    12                                           \n",
            "    13         1        548.0    548.0      0.0      return absorbed\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Lets investigate how the following work:\n",
        "\n",
        "```\n",
        "steps = np.random.rand(N, max_steps)\n",
        "\n",
        "absorbed = np.any(steps < p_abs, axis=1).sum()\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "q_6--UVRIhXR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Low-Level Implementation: steps = np.random.rand(N, max_steps)\n",
        "1. Memory Allocation: Creates a contiguous block of memory for N×max_steps 64-bit floats (8 bytes each)\n",
        "2. RNG Backend: Uses NumPy's optimized C-based implementation\n",
        "3. Vectorization: Generates all numbers in a single native call using SIMD instructions\n",
        "4. Memory Layout: Stores values in row-major order (C-style)"
      ],
      "metadata": {
        "id": "ceEKG1jBOtl9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Low-Level Implementation: absorbed = np.any(steps < p_abs, axis=1).sum()\n",
        "\n",
        "1. Comparison: Creates boolean array via SIMD-accelerated comparison\n",
        "2. Reduction: np.any uses short-circuiting SIMD operations per row\n",
        "3. Summation: Branchless bit-counting optimization for boolean sum"
      ],
      "metadata": {
        "id": "jECzgfNaPBrV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Vectorization always works?"
      ],
      "metadata": {
        "id": "rj1Y_vT3Nfzj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import timeit\n",
        "\n",
        "def loop_add(a, b):\n",
        "    return [x + y for x, y in zip(a, b)]\n",
        "\n",
        "def vec_add(a, b):\n",
        "    return np.array(a) + np.array(b)\n",
        "\n",
        "# Small data: Loop is faster\n",
        "a = list(range(100))\n",
        "b = list(range(100))\n",
        "print(\"Loop:\", timeit.timeit(lambda: loop_add(a, b), number=1000))\n",
        "print(\"Vectorized:\", timeit.timeit(lambda: vec_add(a, b), number=1000))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cEKNfTVTNiqI",
        "outputId": "bf87e395-b0e7-401e-cfc9-78de9a38f1ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loop: 0.008889495999994779\n",
            "Vectorized: 0.025444593000003124\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### If Cython did the job, why to go for vectorization using numpy?"
      ],
      "metadata": {
        "id": "V7yrXvasfG9z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def benchmark_vectorization():\n",
        "    params = [\n",
        "        (1000, 10), # very small\n",
        "        (10_000, 100),    # Small problem\n",
        "        (1_000_000, 100), # Medium problem\n",
        "        (10_000_000, 10)  # Large problem\n",
        "    ]\n",
        "\n",
        "    for N, steps in params:\n",
        "        print(f\"\\nN={N}, steps={steps}\")\n",
        "\n",
        "        # Cython\n",
        "        cy_time = timeit.timeit(lambda: simulate_cython.simulate_cython(N, 0.01, steps), number=10)\n",
        "\n",
        "        print(f\"Cython: {cy_time/10:.4f}s per run\")\n",
        "\n",
        "        # NumPy vectorized\n",
        "        np_time = timeit.timeit(lambda: simulate_numpy(N, 0.01, steps), number=10)\n",
        "        print(f\"NumPy: {np_time/10:.4f}s per run\")\n",
        "\n",
        "benchmark_vectorization()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ou2UoZWfF9q",
        "outputId": "4b78976e-20bf-4a01-c2cb-bddee21d2496"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "N=1000, steps=10\n",
            "Cython: 0.0002s per run\n",
            "NumPy: 0.0003s per run\n",
            "\n",
            "N=10000, steps=100\n",
            "Cython: 0.0129s per run\n",
            "NumPy: 0.0118s per run\n",
            "\n",
            "N=1000000, steps=100\n",
            "Cython: 1.4918s per run\n",
            "NumPy: 1.4204s per run\n",
            "\n",
            "N=10000000, steps=10\n",
            "Cython: 2.3517s per run\n",
            "NumPy: 1.9329s per run\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save the code for memory profiling"
      ],
      "metadata": {
        "id": "a5cLyul3H0MR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile my_script.py\n",
        "import numpy as np\n",
        "\n",
        "def simulate_numpy(N=10_000, p_abs=0.01, max_steps=100):\n",
        "    # Generate all random numbers at once\n",
        "    steps = np.random.rand(N, max_steps)  # Shape: (N, max_steps)\n",
        "\n",
        "    # Check absorption per neutron (any step < p_abs)\n",
        "    absorbed = np.any(steps < p_abs, axis=1).sum()\n",
        "\n",
        "    return absorbed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SeHYWJvUxNq4",
        "outputId": "fd1a0fa3-0b44-4ef2-b550-462266f32d48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing my_script.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Memory profiling"
      ],
      "metadata": {
        "id": "pE9LTRRkf_3W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install memory_profiler"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Mjp7TsVeIfG",
        "outputId": "1b005989-5042-4e03-ca70-2bb8b85c73f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting memory_profiler\n",
            "  Downloading memory_profiler-0.61.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from memory_profiler) (5.9.5)\n",
            "Downloading memory_profiler-0.61.0-py3-none-any.whl (31 kB)\n",
            "Installing collected packages: memory_profiler\n",
            "Successfully installed memory_profiler-0.61.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext memory_profiler\n",
        "from my_script import simulate_numpy\n",
        "from memory_profiler import profile\n",
        "\n",
        "# Memory profiling (run separately)\n",
        "%mprun -f simulate_numpy simulate_numpy(1000000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N6N8VGjZw80s",
        "outputId": "e590f64c-a617-4dbe-9661-4bba01198631"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The memory_profiler extension is already loaded. To reload it, use:\n",
            "  %reload_ext memory_profiler\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lets address some queries\n",
        "0. Why `params` is a list of tuples and not list of lists?\n",
        "1. Whether `lp.add_function(func_name)` and `lp(func_name)` performing same operations? How to invoke line-profiling when the function is added using `lp.add_function` method?\n",
        "2. How broadcasting works in `np.any(steps < p_abs)`?\n",
        "3. What is `number` argument in `timeit.timeit` function call?\n",
        "4. Why `timeit.timeit` expects a lambda instead of a function call as the argument?\n",
        "5. Is there any rule of thumb on when to go for vectorization vs cython implementation to acheive optimal runtime?\n",
        "   1. Depends on memory and compute budget?\n",
        "6. How to make efficient use of memory for large N, max_steps when using vectorization?\n",
        "   1. Application specific optimizations:\n",
        "      1. Minimize the footprint of random array?\n",
        "         1. Lower precision\n",
        "         2. Simpler/Efficient random number generator with lower memory requirements?\n",
        "         3. Allocate only partial chunks of random-array (impacts runtime performance? How much?)\n",
        "         4. Switch to multiprocessing to avoid process-crash due to large memory requirement?\n",
        "            1. Vectorized operation in each process (Hybrid approach between vectorization and multi-process parallelization)\n",
        "               1. Whether resulting runtime performance outweighs communication overheads?"
      ],
      "metadata": {
        "id": "OaHmSMYMEVD-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Performance tradeoff between list of lists vs list of tuples (immutable)"
      ],
      "metadata": {
        "id": "hCKRL-a2SRgJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import timeit\n",
        "import sys\n",
        "\n",
        "def create_list_of_lists(n):\n",
        "    return [[i, i*2] for i in range(n)]\n",
        "\n",
        "def create_list_of_tuples(n):\n",
        "    return [(i, i*2) for i in range(n)]\n",
        "\n",
        "def access_elements_list(data):\n",
        "    for item in data:\n",
        "        a, b = item[0], item[1]\n",
        "\n",
        "def access_elements_tuple(data):\n",
        "    for item in data:\n",
        "        a, b = item[0], item[1]\n",
        "\n",
        "def benchmark():\n",
        "    sizes = [10**3, 10**4, 10**5, 10**6]  # Test different scales\n",
        "\n",
        "    for n in sizes:\n",
        "        print(f\"\\nBenchmarking for size {n}:\")\n",
        "\n",
        "        # Creation time comparison\n",
        "        list_creation = timeit.timeit(lambda: create_list_of_lists(n), number=100)\n",
        "        tuple_creation = timeit.timeit(lambda: create_list_of_tuples(n), number=100)\n",
        "        print(f\"Creation: Lists {list_creation:.5f}s vs Tuples {tuple_creation:.5f}s (Δ {list_creation - tuple_creation:+.4f}s)\")\n",
        "\n",
        "        # Access time comparison\n",
        "        list_data = create_list_of_lists(n)\n",
        "        tuple_data = create_list_of_tuples(n)\n",
        "        list_access = timeit.timeit(lambda: access_elements_list(list_data), number=100)\n",
        "        tuple_access = timeit.timeit(lambda: access_elements_tuple(tuple_data), number=100)\n",
        "        print(f\"Access:   Lists {list_access:.5f}s vs Tuples {tuple_access:.5f}s (Δ {list_access - tuple_access:+.4f}s)\")\n",
        "\n",
        "        # Memory comparison\n",
        "        list_mem = sys.getsizeof(list_data) + sum(sys.getsizeof(x) for x in list_data)\n",
        "        tuple_mem = sys.getsizeof(tuple_data) + sum(sys.getsizeof(x) for x in tuple_data)\n",
        "        print(f\"Memory:   Lists {list_mem:,}b vs Tuples {tuple_mem:,}b (Δ {list_mem - tuple_mem:,}b)\")\n",
        "\n",
        "benchmark()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dVhZhh5jR9sh",
        "outputId": "64cc653b-a260-4863-e4d7-f3721a90884a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Benchmarking for size 1000:\n",
            "Creation: Lists 0.01254s vs Tuples 0.00826s (Δ +0.0043s)\n",
            "Access:   Lists 0.00346s vs Tuples 0.00281s (Δ +0.0006s)\n",
            "Memory:   Lists 80,856b vs Tuples 64,856b (Δ 16,000b)\n",
            "\n",
            "Benchmarking for size 10000:\n",
            "Creation: Lists 0.11037s vs Tuples 0.10218s (Δ +0.0082s)\n",
            "Access:   Lists 0.03922s vs Tuples 0.02720s (Δ +0.0120s)\n",
            "Memory:   Lists 805,176b vs Tuples 645,176b (Δ 160,000b)\n",
            "\n",
            "Benchmarking for size 100000:\n",
            "Creation: Lists 1.95821s vs Tuples 1.40040s (Δ +0.5578s)\n",
            "Access:   Lists 0.33466s vs Tuples 0.31238s (Δ +0.0223s)\n",
            "Memory:   Lists 8,000,984b vs Tuples 6,400,984b (Δ 1,600,000b)\n",
            "\n",
            "Benchmarking for size 1000000:\n",
            "Creation: Lists 24.33007s vs Tuples 19.90192s (Δ +4.4281s)\n",
            "Access:   Lists 3.17035s vs Tuples 3.02470s (Δ +0.1456s)\n",
            "Memory:   Lists 80,448,728b vs Tuples 64,448,728b (Δ 16,000,000b)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### How broadcasting works in Python?"
      ],
      "metadata": {
        "id": "rNE7nPLpXxXM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import timeit\n",
        "\n",
        "def broadcast_demo():\n",
        "    # Example 1: Basic scalar broadcasting\n",
        "    print(\"=== Level 1: Scalar Broadcasting ===\")\n",
        "    arr = np.arange(1, 6)  # Shape: (5,)\n",
        "    result = arr + 5\n",
        "    print(f\"Original: {arr}\\nAfter +5: {result}\\nShape: {result.shape}\\n\")\n",
        "\n",
        "    # Example 2: Vector + Matrix broadcasting\n",
        "    print(\"=== Level 2: Vector-Matrix Broadcasting ===\")\n",
        "    matrix = np.array([[1, 2], [3, 4], [5, 6]])  # (3,2)\n",
        "    vector = np.array([10, 20])                   # (2,)\n",
        "    result = matrix * vector\n",
        "    print(f\"Matrix:\\n{matrix}\\nVector: {vector}\\nResult:\\n{result}\\nShape: {result.shape}\\n\")\n",
        "\n",
        "    # Example 3: 3D + 1D broadcasting\n",
        "    print(\"=== Level 3: 3D/1D Broadcasting ===\")\n",
        "    tensor_3d = np.ones((2, 3, 4))  # (2,3,4)\n",
        "    vector_1d = np.array([1, 2, 3, 4])  # (4,)\n",
        "    result = tensor_3d * vector_1d\n",
        "    print(f\"3D Tensor Shape: {tensor_3d.shape}\")\n",
        "    print(f\"1D Vector Shape: {vector_1d.shape}\")\n",
        "    print(f\"Result Shape: {result.shape}\\nSlice:\\n{result[0,0]}\\n\")\n",
        "\n",
        "    # Example 4: Conditional broadcasting\n",
        "    print(\"=== Level 4: Conditional Broadcasting ===\")\n",
        "    data = np.random.rand(3, 4)  # (3,4)\n",
        "    thresholds = np.array([0.3, 0.5, 0.7])  # (3,)\n",
        "    result = np.where(data > thresholds[:, np.newaxis], 1, 0)\n",
        "    print(f\"Data:\\n{np.round(data,2)}\\nThresholds: {thresholds}\")\n",
        "    print(f\"Result:\\n{result}\\nShape: {result.shape}\\n\")\n",
        "\n",
        "    # Example 5: Complex matrix operations\n",
        "    print(\"=== Level 5: Matrix Outer Product via Broadcasting ===\")\n",
        "    A = np.array([1, 2, 3])  # (3,)\n",
        "    B = np.array([4, 5])      # (2,)\n",
        "    result = A[:, np.newaxis] * B  # Explicit broadcasting\n",
        "    print(f\"A: {A}\\nB: {B}\")\n",
        "    print(f\"Outer Product:\\n{result}\\nShape: {result.shape}\\n\")\n",
        "\n",
        "    # Performance comparison\n",
        "    print(\"=== Performance Scaling ===\")\n",
        "    sizes = [10**3, 10**4, 10**5, 10**6]\n",
        "    for size in sizes:\n",
        "        a = np.random.rand(size)\n",
        "        b = np.random.rand(1)\n",
        "\n",
        "        # Time scalar broadcasting\n",
        "        t_scalar = timeit.timeit(lambda: a + 5, number=100)\n",
        "\n",
        "        # Time array broadcasting\n",
        "        t_array = timeit.timeit(lambda: a + b, number=100)\n",
        "\n",
        "        print(f\"Size {size:>8}: Scalar {t_scalar:.5f}s | Array {t_array:.5f}s\")\n",
        "\n",
        "broadcast_demo()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uHe11MIZX09N",
        "outputId": "d5c78224-5f76-4b3d-d3b9-c389cd448911"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Level 1: Scalar Broadcasting ===\n",
            "Original: [1 2 3 4 5]\n",
            "After +5: [ 6  7  8  9 10]\n",
            "Shape: (5,)\n",
            "\n",
            "=== Level 2: Vector-Matrix Broadcasting ===\n",
            "Matrix:\n",
            "[[1 2]\n",
            " [3 4]\n",
            " [5 6]]\n",
            "Vector: [10 20]\n",
            "Result:\n",
            "[[ 10  40]\n",
            " [ 30  80]\n",
            " [ 50 120]]\n",
            "Shape: (3, 2)\n",
            "\n",
            "=== Level 3: 3D/1D Broadcasting ===\n",
            "3D Tensor Shape: (2, 3, 4)\n",
            "1D Vector Shape: (4,)\n",
            "Result Shape: (2, 3, 4)\n",
            "Slice:\n",
            "[1. 2. 3. 4.]\n",
            "\n",
            "=== Level 4: Conditional Broadcasting ===\n",
            "Data:\n",
            "[[0.92 0.32 0.9  0.78]\n",
            " [0.53 0.   0.66 0.88]\n",
            " [0.38 0.84 0.57 0.03]]\n",
            "Thresholds: [0.3 0.5 0.7]\n",
            "Result:\n",
            "[[1 1 1 1]\n",
            " [1 0 1 1]\n",
            " [0 1 0 0]]\n",
            "Shape: (3, 4)\n",
            "\n",
            "=== Level 5: Matrix Outer Product via Broadcasting ===\n",
            "A: [1 2 3]\n",
            "B: [4 5]\n",
            "Outer Product:\n",
            "[[ 4  5]\n",
            " [ 8 10]\n",
            " [12 15]]\n",
            "Shape: (3, 2)\n",
            "\n",
            "=== Performance Scaling ===\n",
            "Size     1000: Scalar 0.00023s | Array 0.00024s\n",
            "Size    10000: Scalar 0.00054s | Array 0.00064s\n",
            "Size   100000: Scalar 0.00679s | Array 0.00668s\n",
            "Size  1000000: Scalar 0.10825s | Array 0.10221s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### How broadcasting fares against for loops?"
      ],
      "metadata": {
        "id": "pPkeo2NkY0BW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import timeit\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def broadcast_comparison():\n",
        "    # Setup\n",
        "    sizes = [10**3, 10**4, 10**5, 10**6, 10**7]\n",
        "    broadcast_times = []\n",
        "    loop_times = []\n",
        "\n",
        "    print(\"=== Broadcasting vs. Looping Performance ===\")\n",
        "    print(f\"{'Size':>10} | {'Broadcast (ms)':<12} | {'Loop (ms)':<10} | Speedup\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    for size in sizes:\n",
        "        # Create test data\n",
        "        a = np.random.rand(size)\n",
        "        b = np.random.rand(size)\n",
        "        scalar = 5.0\n",
        "\n",
        "        # Benchmark 1: Broadcasting (vectorized)\n",
        "        broadcast_time = timeit.timeit(lambda: a + scalar, number=100) * 10  # Convert to ms\n",
        "        broadcast_times.append(broadcast_time)\n",
        "\n",
        "        # Benchmark 2: Explicit loop (non-vectorized)\n",
        "        def loop_operation():\n",
        "            result = np.empty_like(a)\n",
        "            for i in range(len(a)):\n",
        "                result[i] = a[i] + scalar\n",
        "            return result\n",
        "\n",
        "        loop_time = timeit.timeit(loop_operation, number=100) * 10  # Convert to ms\n",
        "        loop_times.append(loop_time)\n",
        "\n",
        "        # Print comparison\n",
        "        speedup = loop_time / broadcast_time\n",
        "        print(f\"{size:>10,} | {broadcast_time:>10.4f} | {loop_time:>10.4f} | {speedup:>5.1f}x\")\n",
        "\n",
        "    # Plot results\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(sizes, broadcast_times, 'o-', label='Broadcasting')\n",
        "    plt.plot(sizes, loop_times, 's-', label='Explicit Loop')\n",
        "    plt.xscale('log')\n",
        "    plt.yscale('log')\n",
        "    plt.xlabel('Array Size')\n",
        "    plt.ylabel('Time (ms) for 100 operations')\n",
        "    plt.title('Broadcasting vs. Looping Performance')\n",
        "    plt.legend()\n",
        "    plt.grid(True, which=\"both\", ls=\"--\")\n",
        "    plt.show()\n",
        "\n",
        "    # Advanced comparison: Matrix operations\n",
        "    print(\"\\n=== Matrix Operation Comparison ===\")\n",
        "    matrix_sizes = [10, 100, 500, 1000]\n",
        "    for size in matrix_sizes:\n",
        "        A = np.random.rand(size, size)\n",
        "        B = np.random.rand(size, 1)\n",
        "\n",
        "        # Broadcasting approach\n",
        "        def broadcast_matmul():\n",
        "            return A * B  # Broadcasts B across all columns of A\n",
        "\n",
        "        # Loop approach\n",
        "        def loop_matmul():\n",
        "            result = np.empty_like(A)\n",
        "            for i in range(A.shape[0]):\n",
        "                for j in range(A.shape[1]):\n",
        "                    result[i,j] = A[i,j] * B[i,0]\n",
        "            return result\n",
        "\n",
        "        b_time = timeit.timeit(broadcast_matmul, number=10) * 100  # Convert to ms\n",
        "        l_time = timeit.timeit(loop_matmul, number=10) * 100\n",
        "\n",
        "        print(f\"Matrix {size}x{size}: Broadcast {b_time:.2f}ms vs Loop {l_time:.2f}ms ({l_time/b_time:.1f}x slower)\")\n",
        "\n",
        "broadcast_comparison()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1kB36WmSY4KA",
        "outputId": "5fee9fda-215e-4f94-b337-f5f4b5edcc46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Broadcasting vs. Looping Performance ===\n",
            "      Size | Broadcast (ms) | Loop (ms)  | Speedup\n",
            "--------------------------------------------------\n",
            "     1,000 |     0.0121 |     0.2627 |  21.8x\n",
            "    10,000 |     0.0059 |     2.4891 | 424.3x\n",
            "   100,000 |     0.0672 |    37.2000 | 553.5x\n",
            " 1,000,000 |     0.9437 |   285.9427 | 303.0x\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multiprocessing Parallelization\n",
        "\n",
        "Objective: Distribute work across CPU cores."
      ],
      "metadata": {
        "id": "DvzAxbSLKfD0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from multiprocessing import Pool\n",
        "\n",
        "def simulate_neutron(args):\n",
        "    p_abs, max_steps = args\n",
        "    for _ in range(max_steps):\n",
        "        if random.random() < p_abs:\n",
        "            return 1\n",
        "    return 0\n",
        "\n",
        "def simulate_parallel(N=10_000, p_abs=0.01, max_steps=100):\n",
        "    with Pool(2) as pool:  # Use 4 cores\n",
        "        results = pool.map(simulate_neutron, [(p_abs, max_steps)] * N)\n",
        "    return sum(results)\n",
        "start = time.time()\n",
        "print(\"Parallel Result:\", simulate_parallel())\n",
        "print(f\"Parallel Time: {time.time() - start:.4f}s\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OjVVkZS9KhV-",
        "outputId": "4716fee4-581c-46df-9a0b-cca95327fc35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parallel Result: 6328\n",
            "Parallel Time: 0.0978s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explanation:\n",
        "\n",
        "    Pool.map splits N neutrons across workers.\n",
        "\n",
        "    Each neutron simulation is independent (embarrassingly parallel).\n",
        "\n",
        "Assignment:\n",
        "\n",
        "    Benchmark performance for Pool(2) vs. Pool(8) on Google Colab."
      ],
      "metadata": {
        "id": "WmXGzd3JKjeY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lecture 4: GPU Acceleration with CuPy\n",
        "\n",
        "Objective: Offload computation to GPU."
      ],
      "metadata": {
        "id": "ddg6ZFbWKmHs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get update\n",
        "!apt-get install -y --no-install-recommends cuda-drivers\n",
        "\n",
        "# Check driver version to confirm update\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2N5TKADzU2s8",
        "outputId": "b78aa7ea-c4bd-4204-9f64-e1ce78187ea3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "\r0% [Connecting to archive.ubuntu.com (91.189.91.82)] [Connecting to security.ubuntu.com (185.125.190\r0% [Connecting to archive.ubuntu.com (91.189.91.82)] [Connecting to security.ubuntu.com (185.125.190\r                                                                                                    \rGet:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Hit:3 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:4 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:6 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,381 kB]\n",
            "Hit:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:11 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,784 kB]\n",
            "Hit:12 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,043 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,538 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/multiverse amd64 Packages [55.7 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [4,041 kB]\n",
            "Get:17 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,686 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [35.2 kB]\n",
            "Get:19 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,239 kB]\n",
            "Get:20 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,733 kB]\n",
            "Get:21 http://security.ubuntu.com/ubuntu jammy-security/multiverse amd64 Packages [47.7 kB]\n",
            "Get:22 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [3,884 kB]\n",
            "Fetched 29.9 MB in 4s (8,182 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  cpp-12 cuda-drivers-570 dctrl-tools dkms gcc-12 keyboard-configuration libasan8 libfontenc1\n",
            "  libgcc-12-dev liblocale-gettext-perl libnvidia-cfg1-570 libnvidia-common-570\n",
            "  libnvidia-compute-570 libnvidia-decode-570 libnvidia-encode-570 libnvidia-extra-570\n",
            "  libnvidia-fbc1-570 libnvidia-gl-570 libtsan2 libxcvt0 libxfont2 libxkbfile1\n",
            "  nvidia-compute-utils-570 nvidia-dkms-570 nvidia-driver-570 nvidia-firmware-570-570.124.06\n",
            "  nvidia-kernel-common-570 nvidia-kernel-source-570 nvidia-modprobe nvidia-utils-570 udev\n",
            "  x11-xkb-utils xserver-common xserver-xorg-core xserver-xorg-video-nvidia-570\n",
            "Suggested packages:\n",
            "  gcc-12-locales cpp-12-doc debtags menu gcc-12-multilib gcc-12-doc xfonts-100dpi | xfonts-75dpi\n",
            "  xfonts-scalable\n",
            "Recommended packages:\n",
            "  fakeroot switcheroo-control nvidia-settings libnvidia-compute-570:i386 libnvidia-decode-570:i386\n",
            "  libnvidia-encode-570:i386 libnvidia-fbc1-570:i386 libnvidia-gl-570:i386 systemd-hwe-hwdb\n",
            "  xfonts-base xcvt\n",
            "The following NEW packages will be installed:\n",
            "  cpp-12 cuda-drivers cuda-drivers-570 dctrl-tools dkms gcc-12 keyboard-configuration libasan8\n",
            "  libfontenc1 libgcc-12-dev liblocale-gettext-perl libnvidia-cfg1-570 libnvidia-common-570\n",
            "  libnvidia-compute-570 libnvidia-decode-570 libnvidia-encode-570 libnvidia-extra-570\n",
            "  libnvidia-fbc1-570 libnvidia-gl-570 libtsan2 libxcvt0 libxfont2 libxkbfile1\n",
            "  nvidia-compute-utils-570 nvidia-dkms-570 nvidia-driver-570 nvidia-firmware-570-570.124.06\n",
            "  nvidia-kernel-common-570 nvidia-kernel-source-570 nvidia-modprobe nvidia-utils-570 udev\n",
            "  x11-xkb-utils xserver-common xserver-xorg-core xserver-xorg-video-nvidia-570\n",
            "0 upgraded, 36 newly installed, 0 to remove and 37 not upgraded.\n",
            "Need to get 394 MB of archives.\n",
            "After this operation, 1,158 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 liblocale-gettext-perl amd64 1.07-4build3 [17.1 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 keyboard-configuration all 1.205ubuntu3 [206 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 cpp-12 amd64 12.3.0-1ubuntu1~22.04 [10.8 MB]\n",
            "Get:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libnvidia-common-570 570.124.06-0ubuntu1 [15.9 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libasan8 amd64 12.3.0-1ubuntu1~22.04 [2,442 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libtsan2 amd64 12.3.0-1ubuntu1~22.04 [2,477 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgcc-12-dev amd64 12.3.0-1ubuntu1~22.04 [2,618 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 gcc-12 amd64 12.3.0-1ubuntu1~22.04 [21.7 MB]\n",
            "Get:9 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libnvidia-gl-570 570.124.06-0ubuntu1 [162 MB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy/main amd64 dctrl-tools amd64 2.24-3build2 [66.9 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 dkms all 2.8.7-2ubuntu2.2 [70.1 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 udev amd64 249.11-0ubuntu3.12 [1,557 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxkbfile1 amd64 1:1.1.0-1build3 [71.8 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy/main amd64 x11-xkb-utils amd64 7.7+5build4 [172 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 xserver-common all 2:21.1.4-2ubuntu1.7~22.04.13 [29.1 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcvt0 amd64 0.1.1-3 [5,494 B]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy/main amd64 libfontenc1 amd64 1:1.1.4-1build3 [14.7 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxfont2 amd64 1:2.0.5-1build1 [94.5 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 xserver-xorg-core amd64 2:21.1.4-2ubuntu1.7~22.04.13 [1,477 kB]\n",
            "Get:20 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  nvidia-kernel-source-570 570.124.06-0ubuntu1 [73.2 MB]\n",
            "Get:21 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  nvidia-firmware-570-570.124.06 570.124.06-0ubuntu1 [64.5 MB]\n",
            "Get:22 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  nvidia-modprobe 570.124.06-0ubuntu1 [14.9 kB]\n",
            "Get:23 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  nvidia-kernel-common-570 570.124.06-0ubuntu1 [98.6 kB]\n",
            "Get:24 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  nvidia-dkms-570 570.124.06-0ubuntu1 [14.9 kB]\n",
            "Get:25 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libnvidia-decode-570 570.124.06-0ubuntu1 [2,434 kB]\n",
            "Get:26 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libnvidia-compute-570 570.124.06-0ubuntu1 [44.1 MB]\n",
            "Get:27 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libnvidia-extra-570 570.124.06-0ubuntu1 [72.7 kB]\n",
            "Get:28 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  nvidia-compute-utils-570 570.124.06-0ubuntu1 [109 kB]\n",
            "Get:29 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libnvidia-encode-570 570.124.06-0ubuntu1 [105 kB]\n",
            "Get:30 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  nvidia-utils-570 570.124.06-0ubuntu1 [521 kB]\n",
            "Get:31 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libnvidia-cfg1-570 570.124.06-0ubuntu1 [145 kB]\n",
            "Get:32 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  xserver-xorg-video-nvidia-570 570.124.06-0ubuntu1 [1,694 kB]\n",
            "Get:33 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libnvidia-fbc1-570 570.124.06-0ubuntu1 [98.2 kB]\n",
            "Get:34 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  nvidia-driver-570 570.124.06-0ubuntu1 [491 kB]\n",
            "Get:35 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  cuda-drivers-570 570.124.06-0ubuntu1 [2,554 B]\n",
            "Get:36 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  cuda-drivers 570.124.06-0ubuntu1 [2,502 B]\n",
            "Fetched 394 MB in 12s (31.9 MB/s)\n",
            "Extracting templates from packages: 100%\n",
            "Preconfiguring packages ...\n",
            "Selecting previously unselected package liblocale-gettext-perl.\n",
            "(Reading database ... 126209 files and directories currently installed.)\n",
            "Preparing to unpack .../00-liblocale-gettext-perl_1.07-4build3_amd64.deb ...\n",
            "Unpacking liblocale-gettext-perl (1.07-4build3) ...\n",
            "Selecting previously unselected package keyboard-configuration.\n",
            "Preparing to unpack .../01-keyboard-configuration_1.205ubuntu3_all.deb ...\n",
            "Unpacking keyboard-configuration (1.205ubuntu3) ...\n",
            "Selecting previously unselected package cpp-12.\n",
            "Preparing to unpack .../02-cpp-12_12.3.0-1ubuntu1~22.04_amd64.deb ...\n",
            "Unpacking cpp-12 (12.3.0-1ubuntu1~22.04) ...\n",
            "Selecting previously unselected package libasan8:amd64.\n",
            "Preparing to unpack .../03-libasan8_12.3.0-1ubuntu1~22.04_amd64.deb ...\n",
            "Unpacking libasan8:amd64 (12.3.0-1ubuntu1~22.04) ...\n",
            "Selecting previously unselected package libtsan2:amd64.\n",
            "Preparing to unpack .../04-libtsan2_12.3.0-1ubuntu1~22.04_amd64.deb ...\n",
            "Unpacking libtsan2:amd64 (12.3.0-1ubuntu1~22.04) ...\n",
            "Selecting previously unselected package libgcc-12-dev:amd64.\n",
            "Preparing to unpack .../05-libgcc-12-dev_12.3.0-1ubuntu1~22.04_amd64.deb ...\n",
            "Unpacking libgcc-12-dev:amd64 (12.3.0-1ubuntu1~22.04) ...\n",
            "Selecting previously unselected package gcc-12.\n",
            "Preparing to unpack .../06-gcc-12_12.3.0-1ubuntu1~22.04_amd64.deb ...\n",
            "Unpacking gcc-12 (12.3.0-1ubuntu1~22.04) ...\n",
            "Selecting previously unselected package dctrl-tools.\n",
            "Preparing to unpack .../07-dctrl-tools_2.24-3build2_amd64.deb ...\n",
            "Unpacking dctrl-tools (2.24-3build2) ...\n",
            "Selecting previously unselected package dkms.\n",
            "Preparing to unpack .../08-dkms_2.8.7-2ubuntu2.2_all.deb ...\n",
            "Unpacking dkms (2.8.7-2ubuntu2.2) ...\n",
            "Selecting previously unselected package udev.\n",
            "Preparing to unpack .../09-udev_249.11-0ubuntu3.12_amd64.deb ...\n",
            "Unpacking udev (249.11-0ubuntu3.12) ...\n",
            "Selecting previously unselected package libnvidia-common-570.\n",
            "Preparing to unpack .../10-libnvidia-common-570_570.124.06-0ubuntu1_all.deb ...\n",
            "Unpacking libnvidia-common-570 (570.124.06-0ubuntu1) ...\n",
            "Selecting previously unselected package libnvidia-gl-570:amd64.\n",
            "Preparing to unpack .../11-libnvidia-gl-570_570.124.06-0ubuntu1_amd64.deb ...\n",
            "dpkg-query: no packages found matching libnvidia-gl-535\n",
            "Unpacking libnvidia-gl-570:amd64 (570.124.06-0ubuntu1) ...\n",
            "Selecting previously unselected package nvidia-kernel-source-570.\n",
            "Preparing to unpack .../12-nvidia-kernel-source-570_570.124.06-0ubuntu1_amd64.deb ...\n",
            "Unpacking nvidia-kernel-source-570 (570.124.06-0ubuntu1) ...\n",
            "Selecting previously unselected package nvidia-firmware-570-570.124.06.\n",
            "Preparing to unpack .../13-nvidia-firmware-570-570.124.06_570.124.06-0ubuntu1_amd64.deb ...\n",
            "Unpacking nvidia-firmware-570-570.124.06 (570.124.06-0ubuntu1) ...\n",
            "Selecting previously unselected package nvidia-modprobe.\n",
            "Preparing to unpack .../14-nvidia-modprobe_570.124.06-0ubuntu1_amd64.deb ...\n",
            "Unpacking nvidia-modprobe (570.124.06-0ubuntu1) ...\n",
            "Selecting previously unselected package nvidia-kernel-common-570.\n",
            "Preparing to unpack .../15-nvidia-kernel-common-570_570.124.06-0ubuntu1_amd64.deb ...\n",
            "Unpacking nvidia-kernel-common-570 (570.124.06-0ubuntu1) ...\n",
            "Selecting previously unselected package nvidia-dkms-570.\n",
            "Preparing to unpack .../16-nvidia-dkms-570_570.124.06-0ubuntu1_amd64.deb ...\n",
            "Unpacking nvidia-dkms-570 (570.124.06-0ubuntu1) ...\n",
            "Selecting previously unselected package libnvidia-decode-570:amd64.\n",
            "Preparing to unpack .../17-libnvidia-decode-570_570.124.06-0ubuntu1_amd64.deb ...\n",
            "Unpacking libnvidia-decode-570:amd64 (570.124.06-0ubuntu1) ...\n",
            "Selecting previously unselected package libnvidia-compute-570:amd64.\n",
            "Preparing to unpack .../18-libnvidia-compute-570_570.124.06-0ubuntu1_amd64.deb ...\n",
            "Unpacking libnvidia-compute-570:amd64 (570.124.06-0ubuntu1) ...\n",
            "Selecting previously unselected package libnvidia-extra-570:amd64.\n",
            "Preparing to unpack .../19-libnvidia-extra-570_570.124.06-0ubuntu1_amd64.deb ...\n",
            "Unpacking libnvidia-extra-570:amd64 (570.124.06-0ubuntu1) ...\n",
            "Selecting previously unselected package nvidia-compute-utils-570.\n",
            "Preparing to unpack .../20-nvidia-compute-utils-570_570.124.06-0ubuntu1_amd64.deb ...\n",
            "Unpacking nvidia-compute-utils-570 (570.124.06-0ubuntu1) ...\n",
            "Selecting previously unselected package libnvidia-encode-570:amd64.\n",
            "Preparing to unpack .../21-libnvidia-encode-570_570.124.06-0ubuntu1_amd64.deb ...\n",
            "Unpacking libnvidia-encode-570:amd64 (570.124.06-0ubuntu1) ...\n",
            "Selecting previously unselected package nvidia-utils-570.\n",
            "Preparing to unpack .../22-nvidia-utils-570_570.124.06-0ubuntu1_amd64.deb ...\n",
            "Unpacking nvidia-utils-570 (570.124.06-0ubuntu1) ...\n",
            "Selecting previously unselected package libnvidia-cfg1-570:amd64.\n",
            "Preparing to unpack .../23-libnvidia-cfg1-570_570.124.06-0ubuntu1_amd64.deb ...\n",
            "Unpacking libnvidia-cfg1-570:amd64 (570.124.06-0ubuntu1) ...\n",
            "Selecting previously unselected package libxkbfile1:amd64.\n",
            "Preparing to unpack .../24-libxkbfile1_1%3a1.1.0-1build3_amd64.deb ...\n",
            "Unpacking libxkbfile1:amd64 (1:1.1.0-1build3) ...\n",
            "Selecting previously unselected package x11-xkb-utils.\n",
            "Preparing to unpack .../25-x11-xkb-utils_7.7+5build4_amd64.deb ...\n",
            "Unpacking x11-xkb-utils (7.7+5build4) ...\n",
            "Selecting previously unselected package xserver-common.\n",
            "Preparing to unpack .../26-xserver-common_2%3a21.1.4-2ubuntu1.7~22.04.13_all.deb ...\n",
            "Unpacking xserver-common (2:21.1.4-2ubuntu1.7~22.04.13) ...\n",
            "Selecting previously unselected package libxcvt0:amd64.\n",
            "Preparing to unpack .../27-libxcvt0_0.1.1-3_amd64.deb ...\n",
            "Unpacking libxcvt0:amd64 (0.1.1-3) ...\n",
            "Selecting previously unselected package libfontenc1:amd64.\n",
            "Preparing to unpack .../28-libfontenc1_1%3a1.1.4-1build3_amd64.deb ...\n",
            "Unpacking libfontenc1:amd64 (1:1.1.4-1build3) ...\n",
            "Selecting previously unselected package libxfont2:amd64.\n",
            "Preparing to unpack .../29-libxfont2_1%3a2.0.5-1build1_amd64.deb ...\n",
            "Unpacking libxfont2:amd64 (1:2.0.5-1build1) ...\n",
            "Selecting previously unselected package xserver-xorg-core.\n",
            "Preparing to unpack .../30-xserver-xorg-core_2%3a21.1.4-2ubuntu1.7~22.04.13_amd64.deb ...\n",
            "Unpacking xserver-xorg-core (2:21.1.4-2ubuntu1.7~22.04.13) ...\n",
            "Selecting previously unselected package xserver-xorg-video-nvidia-570.\n",
            "Preparing to unpack .../31-xserver-xorg-video-nvidia-570_570.124.06-0ubuntu1_amd64.deb ...\n",
            "Unpacking xserver-xorg-video-nvidia-570 (570.124.06-0ubuntu1) ...\n",
            "Selecting previously unselected package libnvidia-fbc1-570:amd64.\n",
            "Preparing to unpack .../32-libnvidia-fbc1-570_570.124.06-0ubuntu1_amd64.deb ...\n",
            "Unpacking libnvidia-fbc1-570:amd64 (570.124.06-0ubuntu1) ...\n",
            "Selecting previously unselected package nvidia-driver-570.\n",
            "Preparing to unpack .../33-nvidia-driver-570_570.124.06-0ubuntu1_amd64.deb ...\n",
            "Unpacking nvidia-driver-570 (570.124.06-0ubuntu1) ...\n",
            "Selecting previously unselected package cuda-drivers-570.\n",
            "Preparing to unpack .../34-cuda-drivers-570_570.124.06-0ubuntu1_amd64.deb ...\n",
            "Unpacking cuda-drivers-570 (570.124.06-0ubuntu1) ...\n",
            "Selecting previously unselected package cuda-drivers.\n",
            "Preparing to unpack .../35-cuda-drivers_570.124.06-0ubuntu1_amd64.deb ...\n",
            "Unpacking cuda-drivers (570.124.06-0ubuntu1) ...\n",
            "Setting up nvidia-firmware-570-570.124.06 (570.124.06-0ubuntu1) ...\n",
            "Setting up cpp-12 (12.3.0-1ubuntu1~22.04) ...\n",
            "Setting up libnvidia-extra-570:amd64 (570.124.06-0ubuntu1) ...\n",
            "Setting up nvidia-kernel-source-570 (570.124.06-0ubuntu1) ...\n",
            "Setting up nvidia-modprobe (570.124.06-0ubuntu1) ...\n",
            "Setting up libfontenc1:amd64 (1:1.1.4-1build3) ...\n",
            "Setting up libnvidia-common-570 (570.124.06-0ubuntu1) ...\n",
            "Setting up libnvidia-cfg1-570:amd64 (570.124.06-0ubuntu1) ...\n",
            "Setting up udev (249.11-0ubuntu3.12) ...\n",
            "invoke-rc.d: could not determine current runlevel\n",
            "invoke-rc.d: policy-rc.d denied execution of start.\n",
            "Setting up libasan8:amd64 (12.3.0-1ubuntu1~22.04) ...\n",
            "Setting up libxcvt0:amd64 (0.1.1-3) ...\n",
            "Setting up libxkbfile1:amd64 (1:1.1.0-1build3) ...\n",
            "Setting up libtsan2:amd64 (12.3.0-1ubuntu1~22.04) ...\n",
            "Setting up libxfont2:amd64 (1:2.0.5-1build1) ...\n",
            "Setting up liblocale-gettext-perl (1.07-4build3) ...\n",
            "Setting up libnvidia-fbc1-570:amd64 (570.124.06-0ubuntu1) ...\n",
            "Setting up dctrl-tools (2.24-3build2) ...\n",
            "Setting up nvidia-kernel-common-570 (570.124.06-0ubuntu1) ...\n",
            "Setting up libnvidia-gl-570:amd64 (570.124.06-0ubuntu1) ...\n",
            "Setting up x11-xkb-utils (7.7+5build4) ...\n",
            "Setting up libgcc-12-dev:amd64 (12.3.0-1ubuntu1~22.04) ...\n",
            "Setting up xserver-common (2:21.1.4-2ubuntu1.7~22.04.13) ...\n",
            "Setting up keyboard-configuration (1.205ubuntu3) ...\n",
            "Your console font configuration will be updated the next time your system\n",
            "boots. If you want to update it now, run 'setupcon' from a virtual console.\n",
            "Setting up xserver-xorg-core (2:21.1.4-2ubuntu1.7~22.04.13) ...\n",
            "Setting up gcc-12 (12.3.0-1ubuntu1~22.04) ...\n",
            "Setting up xserver-xorg-video-nvidia-570 (570.124.06-0ubuntu1) ...\n",
            "Setting up dkms (2.8.7-2ubuntu2.2) ...\n",
            "Setting up nvidia-dkms-570 (570.124.06-0ubuntu1) ...\n",
            "Loading new nvidia-570.124.06 DKMS files...\n",
            "It is likely that 6.1.85+ belongs to a chroot's host\n",
            "Building for 5.15.0-134-generic\n",
            "Building for architecture x86_64\n",
            "Building initial module for 5.15.0-134-generic\n",
            "Done.\n",
            "\n",
            "nvidia.ko:\n",
            "Running module version sanity check.\n",
            " - Original module\n",
            "   - No original module exists within this kernel\n",
            " - Installation\n",
            "   - Installing to /lib/modules/5.15.0-134-generic/updates/dkms/\n",
            "\n",
            "nvidia-modeset.ko:\n",
            "Running module version sanity check.\n",
            " - Original module\n",
            "   - No original module exists within this kernel\n",
            " - Installation\n",
            "   - Installing to /lib/modules/5.15.0-134-generic/updates/dkms/\n",
            "\n",
            "nvidia-drm.ko:\n",
            "Running module version sanity check.\n",
            " - Original module\n",
            "   - No original module exists within this kernel\n",
            " - Installation\n",
            "   - Installing to /lib/modules/5.15.0-134-generic/updates/dkms/\n",
            "\n",
            "nvidia-uvm.ko:\n",
            "Running module version sanity check.\n",
            " - Original module\n",
            "   - No original module exists within this kernel\n",
            " - Installation\n",
            "   - Installing to /lib/modules/5.15.0-134-generic/updates/dkms/\n",
            "\n",
            "nvidia-peermem.ko:\n",
            "Running module version sanity check.\n",
            " - Original module\n",
            "   - No original module exists within this kernel\n",
            " - Installation\n",
            "   - Installing to /lib/modules/5.15.0-134-generic/updates/dkms/\n",
            "\n",
            "depmod...\n",
            "Setting up libnvidia-decode-570:amd64 (570.124.06-0ubuntu1) ...\n",
            "Setting up libnvidia-compute-570:amd64 (570.124.06-0ubuntu1) ...\n",
            "Setting up libnvidia-encode-570:amd64 (570.124.06-0ubuntu1) ...\n",
            "Setting up nvidia-utils-570 (570.124.06-0ubuntu1) ...\n",
            "Setting up nvidia-compute-utils-570 (570.124.06-0ubuntu1) ...\n",
            "Setting up nvidia-driver-570 (570.124.06-0ubuntu1) ...\n",
            "Setting up cuda-drivers-570 (570.124.06-0ubuntu1) ...\n",
            "Setting up cuda-drivers (570.124.06-0ubuntu1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for dbus (1.12.20-2ubuntu4.1) ...\n",
            "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install cupy-cuda11x  # Install CuPy for Colab GPU\n",
        "\n",
        "import cupy as cp\n",
        "\n",
        "def simulate_gpu(N=10_000, p_abs=0.01, max_steps=100):\n",
        "    steps = cp.random.rand(N, max_steps)\n",
        "    return (cp.any(steps < p_abs, axis=1)).sum()\n",
        "\n",
        "start = time.time()\n",
        "result = simulate_gpu().get()  # Move data from GPU to CPU\n",
        "print(f\"GPU Result: {result} | Time: {time.time() - start:.4f}s\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 495
        },
        "id": "GyJpFBOkKogN",
        "outputId": "3dae1153-c837-4520-b98b-66af769c4e3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: cupy-cuda11x in /usr/local/lib/python3.11/dist-packages (13.4.1)\n",
            "Requirement already satisfied: numpy<2.3,>=1.22 in /usr/local/lib/python3.11/dist-packages (from cupy-cuda11x) (2.0.2)\n",
            "Requirement already satisfied: fastrlock>=0.5 in /usr/local/lib/python3.11/dist-packages (from cupy-cuda11x) (0.8.3)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "CUDARuntimeError",
          "evalue": "cudaErrorInsufficientDriver: CUDA driver version is insufficient for CUDA runtime version",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mCUDARuntimeError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-003887452a40>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msimulate_gpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Move data from GPU to CPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"GPU Result: {result} | Time: {time.time() - start:.4f}s\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-003887452a40>\u001b[0m in \u001b[0;36msimulate_gpu\u001b[0;34m(N, p_abs, max_steps)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msimulate_gpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10_000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_abs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0msteps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mp_abs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/cupy/random/_sample.py\u001b[0m in \u001b[0;36mrand\u001b[0;34m(*size, **kwarg)\u001b[0m\n\u001b[1;32m     42\u001b[0m         raise TypeError('rand() got unexpected keyword arguments %s'\n\u001b[1;32m     43\u001b[0m                         % ', '.join(kwarg.keys()))\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrandom_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/cupy/random/_sample.py\u001b[0m in \u001b[0;36mrandom_sample\u001b[0;34m(size, dtype)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \"\"\"\n\u001b[0;32m--> 155\u001b[0;31m     \u001b[0mrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_random_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/cupy/random/_generator.py\u001b[0m in \u001b[0;36mget_random_state\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1299\u001b[0m     \"\"\"\n\u001b[0;32m-> 1300\u001b[0;31m     \u001b[0mdev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1301\u001b[0m     \u001b[0mrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_random_states\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1302\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mcupy/cuda/device.pyx\u001b[0m in \u001b[0;36mcupy.cuda.device.Device.__init__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mcupy_backends/cuda/api/runtime.pyx\u001b[0m in \u001b[0;36mcupy_backends.cuda.api.runtime.getDevice\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mcupy_backends/cuda/api/runtime.pyx\u001b[0m in \u001b[0;36mcupy_backends.cuda.api.runtime.check_status\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mCUDARuntimeError\u001b[0m: cudaErrorInsufficientDriver: CUDA driver version is insufficient for CUDA runtime version"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explanation:\n",
        "\n",
        "    cp.random.rand generates random numbers on the GPU.\n",
        "\n",
        "    Operations like cp.any execute in parallel on GPU threads.\n",
        "\n",
        "Assignment:\n",
        "\n",
        "    Test with max_steps=1000 and compare GPU/CPU runtimes."
      ],
      "metadata": {
        "id": "9tEpvWPnKqvj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lecture 5: Variance Reduction Techniques\n",
        "\n",
        "Objective: Implement Russian Roulette for faster convergence."
      ],
      "metadata": {
        "id": "TAL_vWFNKtcf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def simulate_russian_roulette(N=10_000, p_abs=0.01, survival_prob=0.5):\n",
        "    absorbed = 0\n",
        "    for _ in range(N):\n",
        "        weight = 1.0\n",
        "        while True:\n",
        "            if random.random() < p_abs:\n",
        "                absorbed += weight\n",
        "                break\n",
        "            # Russian Roulette: Kill neutron with 50% probability\n",
        "            if random.random() > survival_prob:\n",
        "                break\n",
        "            weight /= survival_prob  # Adjust weight\n",
        "    return absorbed\n",
        "\n",
        "print(\"With Variance Reduction:\", simulate_russian_roulette())"
      ],
      "metadata": {
        "id": "2bvMwj_UKvuB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explanation:\n",
        "\n",
        "    Low-weight neutrons are probabilistically terminated to save computation.\n",
        "\n",
        "    survival_prob balances computation and statistical bias.\n",
        "\n",
        "Assignment:\n",
        "\n",
        "    Compare convergence rates with/without Russian Roulette."
      ],
      "metadata": {
        "id": "4Jv9I2knKyWN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lecture 6: OpenMC Reactor Simulation\n",
        "\n",
        "Objective: Simulate a 3D fuel rod using OpenMC."
      ],
      "metadata": {
        "id": "nAQltdkCK1L4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --pre openmc\n",
        "!python -m openmc.install\n",
        "\n",
        "import openmc\n",
        "\n",
        "# Define materials\n",
        "fuel = openmc.Material()\n",
        "fuel.add_element('U', 1.0, enrichment=4.25)\n",
        "fuel.set_density('g/cm3', 10.0)\n",
        "\n",
        "# Define geometry\n",
        "sphere = openmc.Sphere(r=100.0)\n",
        "cell = openmc.Cell(fill=fuel, region=-sphere)\n",
        "geometry = openmc.Geometry([cell])\n",
        "\n",
        "# Settings\n",
        "settings = openmc.Settings()\n",
        "settings.particles = 1000\n",
        "settings.batches = 10\n",
        "\n",
        "# Run simulation\n",
        "model = openmc.Model(geometry=geometry, materials=openmc.Materials([fuel]), settings=settings)\n",
        "model.run()"
      ],
      "metadata": {
        "id": "_sBrpUc_K3oz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explanation:\n",
        "\n",
        "    OpenMC uses real nuclear data libraries (e.g., ENDF/B-VIII).\n",
        "\n",
        "    Tallies track absorption, fission, etc., in 3D geometry.\n",
        "\n",
        "Assignment:\n",
        "\n",
        "    Add a water moderator around the fuel and compare absorption rates."
      ],
      "metadata": {
        "id": "7S3dU6D5K5tT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lecture 7: Error Analysis\n",
        "\n",
        "Objective: Compute statistical uncertainty."
      ],
      "metadata": {
        "id": "LDEZgf56K8TW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def simulate_with_error(N=10_000, p_abs=0.01, n_batches=10):\n",
        "    results = []\n",
        "    for _ in range(n_batches):\n",
        "        absorbed = simulate_numpy(N // n_batches, p_abs)\n",
        "        results.append(absorbed)\n",
        "    mean = np.mean(results)\n",
        "    std = np.std(results) / np.sqrt(n_batches)\n",
        "    return mean, std\n",
        "\n",
        "mean, std = simulate_with_error()\n",
        "print(f\"Absorption: {mean:.1f} ± {2*std:.1f} (95% CI)\")"
      ],
      "metadata": {
        "id": "N7yWuSFbK-i4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explanation:\n",
        "\n",
        "    Batches reduce correlation between samples.\n",
        "\n",
        "    Standard error decreases as 1/sqrt(n_batches).\n",
        "\n",
        "Assignment:\n",
        "\n",
        "    Plot confidence intervals vs. number of batches."
      ],
      "metadata": {
        "id": "D_55CwbFLAai"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lecture 8: MPI for HPC\n",
        "\n",
        "Objective: Scale simulations across nodes."
      ],
      "metadata": {
        "id": "zyNFe3JALCuy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mpi4py\n",
        "\n",
        "from mpi4py import MPI\n",
        "\n",
        "comm = MPI.COMM_WORLD\n",
        "rank = comm.Get_rank()\n",
        "size = comm.Get_size()\n",
        "\n",
        "def simulate_mpi(N=10_000, p_abs=0.01):\n",
        "    chunk = N // size\n",
        "    local_absorbed = simulate_numpy(chunk, p_abs)\n",
        "    total = comm.reduce(local_absorbed, op=MPI.SUM)\n",
        "    if rank == 0:\n",
        "        return total\n",
        "\n",
        "print(\"MPI Result:\", simulate_mpi())"
      ],
      "metadata": {
        "id": "XleF0GO8LE5Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explanation:\n",
        "\n",
        "    mpi4py splits N neutrons across MPI ranks.\n",
        "\n",
        "    comm.reduce aggregates results to rank 0.\n",
        "\n",
        "Assignment:\n",
        "\n",
        "    Run on 4 MPI processes and measure weak scaling efficiency."
      ],
      "metadata": {
        "id": "zrmIsDxWLIw5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lecture 9: ML for Variance Reduction\n",
        "\n",
        "Objective: Use a neural network to guide neutron paths."
      ],
      "metadata": {
        "id": "kjiCet2yLKBn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Train a surrogate model to predict absorption probability\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(32, activation='relu', input_shape=(3,)),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# Hybrid simulation (pseudo-code)\n",
        "def simulate_ml(N=1000):\n",
        "    absorbed = 0\n",
        "    for _ in range(N):\n",
        "        position = np.random.rand(3)  # 3D position\n",
        "        p_abs_pred = model.predict(position.reshape(1, -1))[0][0]\n",
        "        if random.random() < p_abs_pred:\n",
        "            absorbed += 1\n",
        "    return absorbed"
      ],
      "metadata": {
        "id": "50qqczujLMVY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explanation:\n",
        "\n",
        "    The neural network predicts location-dependent absorption probabilities.\n",
        "\n",
        "    Simulations focus on high-probability regions.\n",
        "\n",
        "Assignment:\n",
        "\n",
        "    Train the model on OpenMC data and compare convergence rates."
      ],
      "metadata": {
        "id": "aquh8ZhOLOgb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lecture 10: Final Project\n",
        "\n",
        "Objective: Optimize a 2D reactor simulation.\n",
        "Guidelines:\n",
        "\n",
        "    Combine GPU acceleration (CuPy), variance reduction, and MPI.\n",
        "\n",
        "    Compare runtime/accuracy trade-offs.\n",
        "\n",
        "    Visualize neutron flux distribution."
      ],
      "metadata": {
        "id": "v4fJU8PwLREC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2D reactor core with materials\n",
        "def simulate_2d_reactor(size=100):\n",
        "    flux = np.zeros((size, size))\n",
        "    for _ in range(N):\n",
        "        x, y = np.random.randint(0, size, 2)\n",
        "        # Track neutron path in 2D grid\n",
        "        ...\n",
        "    return flux"
      ],
      "metadata": {
        "id": "JIHHutl5LTwo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "IOAH8iyVLViC"
      }
    }
  ]
}